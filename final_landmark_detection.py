# -*- coding: utf-8 -*-
"""Final_landmark_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rc-Q1fTdsIBSk90VSu8XJBBJdrkd-mgm

# Landmark Detection with Machine Learning
"""

import matplotlib.pyplot as plt

from PIL import Image

from random import randint

import pandas as pd

import numpy as np

from tqdm import tqdm

import urllib
import cv2
import plotly.express as px

import torch
import torchvision

import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

# loading train data
df_train = pd.read_csv('train1.csv')
print(df_train.head())

df_boxes_split1 = pd.read_csv('boxes_split1.csv')
df_boxes_split2 = pd.read_csv('boxes_split2.csv')
df_boxes = pd.concat([df_boxes_split1, df_boxes_split2])

print(df_boxes.head())

df_train = pd.merge(df_train, df_boxes, on='id',  how='right')
df_train.head()

import pandas as pd
import numpy as np
import csv

train_df = pd.read_csv("train1.csv")
test_df = pd.read_csv("test.csv")
submission = pd.read_csv("./sample_submission.csv")

"""## EDA of Dataset"""

### Get top 100 most frequently appearing landmark_id from the original dataset

rank_number = 100 # Number of top most frequent landmark_id for image selection
sampling_rate = 0.02 # fraction of images from each landmark_id
random_state = 17 # for reproducibility

landmarks=train_df.groupby(by='landmark_id').count().loc[:,'id']
l = landmarks.sort_values(ascending=False)

#l=landmarks.sample(frac=1,random_state=random_state)
lmks = pd.concat([l, l/l.sum(), l.cumsum()/l.sum()], axis=1, ignore_index=True)
lmks.columns=['Count', 'Proportion', 'CumSum']
ranked = lmks[0:rank_number]

train_ordered = train_df[train_df.landmark_id.isin(ranked.index)]
sample_gby = train_ordered.groupby(by='landmark_id').apply(lambda x: x.sample(frac=sampling_rate, random_state=random_state))
sample_idx = sample_gby.index.levels[1]
train_sample = train_df.iloc[sample_idx, :]

# write to csv file
train_sample.to_csv('train_sample.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)
train_sample_df = pd.read_csv('train_sample.csv')

train_sample.head()



print("Total training data size:", train_df.shape[0])
print("Total test data size:", test_df.shape[0])
print("Total number of unique landmark_id's:", len(landmarks))

print("Sampled training data size:", train_sample.shape[0])
print("Sampled unique landmark_id's:", len(train_sample["landmark_id"].unique()))

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

### Frequency of landmark_id in dataset

plt.figure(figsize = (14, 6))
g = sns.countplot(x="landmark_id", data=train_sample)
g.set_title("Frequency of landmark_id", fontweight="bold", fontsize=12)
plt.xticks(rotation=90)
plt.show()

# Top 10 frequent landmark_ids

train_sample['landmark_id'].value_counts()[:10]

train_sample.nunique()

landmark_dist = train_sample['landmark_id'].value_counts() / train_sample.shape[0]
landmark_dist.head()

plt.figure(figsize = (12, 5))
fig = plt.bar(range(100), landmark_dist)
plt.xlabel("landmark")
plt.ylabel("Proportion of landmark in training set")
plt.savefig('class_dist.png')

landmark = train_df.landmark_id.value_counts()
landmark_df = pd.DataFrame({'landmark_id':landmark.index, 'frequency':landmark.values}).head(30)

landmark_df['landmark_id'] =   landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')

fig = px.bar(landmark_df, x="frequency", y="landmark_id",color='landmark_id',
             hover_data=["landmark_id", "frequency"],
             height=1000,
             title='Number of images per landmark_id (Top 30 landmark_ids)',
             color_discrete_sequence=px.colors.sequential.RdBu)
fig.show()

landmark.hist()

sns.set()
plt.title('Training set: number of images per class(line plot)')
sns.set_color_codes("pastel")
landmarks_fold = pd.DataFrame(train_df['landmark_id'].value_counts())
landmarks_fold.reset_index(inplace=True)
landmarks_fold.columns = ['landmark_id','count']
ax = landmarks_fold['count'].plot(logy=True, grid=True)
locs, labels = plt.xticks()
plt.setp(labels, rotation=30)
ax.set(xlabel="Landmarks", ylabel="Number of images")
plt.show()

sns.set()
ax = landmarks_fold.boxplot(column='count')
ax.set_yscale('log')

landmark.describe().transpose()

train_df.isnull().sum()

value_counts = train_df['landmark_id'].value_counts() # normalize=True returns relative frequency

freq_df = pd.DataFrame(value_counts)
freq_df.reset_index(inplace=True)
freq_df.columns = ['landmark_id','frequency']
freq_df

"""# random horizontal flip with 50% probability"""

def get_transform(train):
    transforms = []
    if train:
        
        transforms.append(T.RandomHorizontalFlip(0.5))
    return T.Compose(transforms)

class GoogleLandmarks(Dataset):
    def __init__(self, df, transforms):
        self.df = df
        self.dim = (512, 512)
        self.transforms = transforms
        self.ids = np.unique(df['landmark_id'].values)
        self.ids_dic = {v:k for k,v in enumerate(self.ids)}
    
    def url_to_image(self, url, dim):
        try:
            resp = urllib.request.urlopen(url)
        except:
            return np.array([])
        image = np.asarray(bytearray(resp.read()), dtype="uint8")
        if(image.size != 0):
            image = cv2.imdecode(image, cv2.IMREAD_COLOR)
            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
            image = Image.fromarray(np.uint8(image))
            if(image):
                image = self.transforms(image)
        else:
            image = Image.fromarray(image)
        return T.ToTensor()(image)
    
    def get_rect(self, boxes):
        try:
            y = boxes[0]
            x = boxes[1]
            h = boxes[2] - boxes[0]
            w = boxes[3] - boxes[1]
        except:
            return None
        return plt.Rectangle((x, y), w, h, color='y', alpha=0.3)
    
    def draw_bbox(self, img, rect):
        fig, ax = plt.subplots()
        plt.imshow(img.permute(1, 2, 0))
        if(rect):
            ax.add_patch(rect)
    
    def format_boxes(self, boxes, dim):
        return (np.array(boxes.split(' ')).astype(np.float32) * dim[0]).astype(np.int64)
    
    def __getitem__(self, idx):
        id = self.df.iloc[idx].id
        landmarkid = self.df.iloc[idx].landmark_id
        url = self.df[self.df.id == id].url.values[0]
        boxes = self.df[self.df.id == id].box.values[0]
        
        
        # format boxes
        boxes = self.format_boxes(boxes, self.dim)
        
        labels = np.eye(len(self.ids))[self.ids_dic[landmarkid]]
        
        target = {}
        target["boxes"] = torch.as_tensor([boxes], dtype=torch.int64)
        target["labels"] = torch.as_tensor(labels, dtype=torch.int64)
        target["image_id"] = torch.tensor([idx])
        target["area"] = (boxes[3] - boxes[1]) * (boxes[2] - boxes[0])
        target["iscrowd"] = torch.zeros((1,), dtype=torch.int64)
        
        image = self.url_to_image(url, self.dim)
        
        if(len(image) == 0):
            return None, None
        
        return image, target
        
    def __len__(self):
        return len(self.ids)

# select 10 ids randomly
idxes = [randint(0, len(df_train) - 1) for i in range(10)]

# select only 10 landmarks
ids_of_landmarks = df_train['landmark_id'][idxes].values

# subset of training data with 10 landmarks
df = df_train[df_train['landmark_id'].isin(ids_of_landmarks)]

# google dataset
google_ds = GoogleLandmarks(df, get_transform(train=True))

image, target = google_ds[0]

rect = google_ds.get_rect(target['boxes'][0])
google_ds.draw_bbox(image, rect)

def collate_fn(batch):
    return tuple(zip(*batch))

data_loader = torch.utils.data.DataLoader(
        google_ds, batch_size=8, shuffle=True, num_workers=4,
        collate_fn=collate_fn)

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

"""# Model faster R-CNN Error Epoch"""

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)

num_classes = 2
in_features = model.roi_heads.box_predictor.cls_score.in_features

model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
model = model.to(device)

params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)

# and a learning rate scheduler
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)

total_errors = []
for epoch in range(10):
    losses_arr = []

    for images, targets in data_loader:

        images = list(image.to(device) for image in images if image is not None)
        targets = [{k: torch.as_tensor(v).detach().to(device) for k, v in t.items()} for t in targets if t is not None]

        optimizer.zero_grad()

        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        losses_arr.append(losses.item())

        losses.backward()
        optimizer.step()

        # update the learning rate
        # lr_scheduler.step()
        
    total_errors.append(np.mean(np.array(losses_arr)))
    if epoch % 1 == 0:
        print("Epoch:{0:3d}, Loss:{1:1.3f}".format(epoch, total_errors[-1]))

plt.plot(total_errors)



"""# Resnet 50"""

!pip install keras
!pip install Keras-Applications
from keras import applications

from keras.applications.resnet import ResNet50, preprocess_input, decode_predictions
from keras.preprocessing import image
from keras.models import Model

import matplotlib.pyplot as plt
import numpy as np
from tqdm.auto import tqdm

model = ResNet50(weights='imagenet')

model_cut = Model(inputs=model.inputs, outputs=model.layers[-2].output)

import csv
with open("train1.csv", "r", encoding="utf8") as f:
    train_set = [{k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True)]

train_set[0]

"""# Preparing the images """

from PIL import Image
import io
import urllib

def get_image(URL):
    with urllib.request.urlopen(URL) as url:
        img = Image.open(io.BytesIO(url.read()))
        img = img.convert("RGB")
        img = img.resize((224, 224))
    return img

def preprocess_img(img): 
    x1 = image.img_to_array(img)
    x1 = x1[np.newaxis] 
    x1 = preprocess_input(x1)
    return x1

"""# Calculating embeddings for each monument"""

def pass_img_to_model(x):
    return model_cut.predict(x)

embeddings = []
for instance in tqdm(train_set[:1000]): 
    try:
        embeddings.append({"id": instance["id"], "url" : instance["url"], "embedding": pass_img_to_model(preprocess_img(get_image(instance["url"])))})
    except:
        pass

embeddings[0]

"""# Find images with the same monuments"""

def find_most_similar_imgs(URL, seuil):
    similar_imgs = []
    
    vec_url = np.array(pass_img_to_model(preprocess_img(get_image(URL)))[0])
    vec_url = vec_url / np.linalg.norm(vec_url)
    
    for embedding in embeddings:
        vec_emb = np.array(embedding['embedding'][0])
        vec_emb = vec_emb / np.linalg.norm(vec_emb) 
        similarity = np.dot(vec_url, vec_emb)
        if similarity >= seuil:
            similar_imgs.append((embedding['url'],similarity))
    
    return similar_imgs

"""# Image reference

"""

URL_REF = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/1200px-Colosseo_2020.jpg"

plt.imshow(get_image(URL_REF))

"""# We compare with all images"""



sim_things = find_most_similar_imgs(URL_REF ,0.7)
sim_things.sort(reverse = True, key = lambda x: x[1])

"""# Results"""

import matplotlib.pyplot as plt
for url, val in sim_things:
    plt.imshow(get_image(url))
    plt.show()
    print("similarité: " ,val)
    print()



"""## Create train, validation and test dataset for Faster R-CNN

### Stratified sampling of training, validation and test dataset with 0.8, 0.4 and 0.1 split
"""

from sklearn.model_selection import StratifiedShuffleSplit

X = train_sample_df['id']
y = train_sample_df['landmark_id']

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=10)

for train_id, test_id in sss.split(X, y):
    X_train, X_tmp = X.iloc[train_id], X.iloc[test_id]
    y_train, y_tmp = y.iloc[train_id], y.iloc[test_id]

sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=10)

for train_id, test_id in sss1.split(X_tmp, y_tmp):
    X_valid, X_test = X_tmp.iloc[train_id], X_tmp.iloc[test_id]
    y_valid, y_test = y_tmp.iloc[train_id], y_tmp.iloc[test_id]

"""## Benchmark Model (Random Guessing)
### Expected accuracy
"""

from itertools import combinations

def expected_acc(prob_id):
    
    prob_id_c = 1 - prob_id
    prob_correct_number = []

    for i in range(len(prob_id)+1):

        id_comb = list(combinations(range(len(prob_id)), r=i))
        id_notcomb = [tuple(set(range(len(prob_id)))^set(x)) for x in id_comb]

        prob_comb = np.array([[prob_id[x] for x in id_comb[i]] for i in range(len(id_comb))])
        prob_notcomb = np.array([[prob_id_c[x] for x in id_notcomb[i]] for i in range(len(id_notcomb))])

        prob_num = np.hstack((prob_comb, prob_notcomb))
        ss = sum([np.prod(x) for x in prob_num])

        prob_correct_number.append(ss)

    expected_correct_num = sum(np.array(range(len(prob_id)+1)) * np.array(prob_correct_number))
    expected_accuracy = expected_correct_num / len(prob_id)
    
    return([expected_correct_num, expected_accuracy])

"""### Monte Carlo simulation of expected accuracy"""

import random

### Calculate probability of correctly classifying a landmark_id, P(id)

# prob_id = np.array([0.25, 0.1]) # Example tryout given the probability of two images

prob_id = np.array([(y_test == id).sum() / len(y_test) for id in y_test]) # Calculates probabilities of all landmark_id
seed = [3, 10, 27, 31, 48, 55, 67, 95, 105, 117]

expected_val_df = pd.DataFrame(columns=['E(x)', 'Accuracy'])

for i in seed:
    
    random.seed(i)
    randsample = random.sample(range(len(y_test)), 20)
    
    prob_id_montecarlo = prob_id[randsample]  # random selection of 20 images (instead of total test dataset)
    expected_val_df.loc[len(expected_val_df)] = expected_acc(prob_id_montecarlo)

expected_val_df

round(expected_val_df.T,3)

expected_val_df.mean()

import os
from keras.preprocessing import image                  
from tqdm import tqdm

img_shape = (192, 256) # Image shape (height, width)

def path_to_tensor(img_path):
    # loads RGB image as PIL.Image.Image type
    img = image.load_img(img_path, target_size=img_shape)
    
    # convert PIL.Image.Image type to 3D tensor with shape (192, 256, 3)
    x = image.img_to_array(img)
    
    # convert 3D tensor to 4D tensor with shape (1, 192, 256, 3) and return 4D tensor
    return np.expand_dims(x, axis=0)

def paths_to_tensor(img_paths):
    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]
    return np.vstack(list_of_tensors)

from glob import glob
import os

# define function to load train, test, and validation datasets
train_path = './train_images/'
valid_path = './valid_images/'
test_path = './test_images/'

def load_dataset(path, train_sample):
    file_out = sorted(glob(path + '*'))
    file_out = np.array([s.replace("\\", "/") for s in file_out])
    
    label_out = pd.Series(name="landmark_id")
    
    for file in file_out:
        filebase = os.path.basename(file)
        name = os.path.splitext(filebase)[0]
        temp = train_sample.landmark_id[train_sample["id"] == name]
        label_out = label_out.append(temp)
        
    label_out = np.array(pd.get_dummies(label_out))
    
    return file_out, label_out

from keras import optimizers
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint

input_shape = img_shape + (3,)

model = Sequential()

model.add(Conv2D(filters=16, kernel_size=4, padding='same', activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(100, activation='softmax'))

model.summary()

## Model Evaluation for Faster R-CNN

hist_BaseCNN = {'acc': [0.13132716049382717, 0.17654320987654321, 0.22330246913580246, 0.28456790123456788, 0.36003086419753089,
                        0.44645061728395063, 0.54243827160493829, 0.65416666666666667, 0.75169753086419755, 0.8246913580246914],
                'loss': [3.9298892386165667, 3.680104664814325, 3.3804817258575817, 3.066348374920127, 2.6730856707066666,
                         2.2241253917599901, 1.7646778118463211, 1.286705630502583, 0.87414459122551813, 0.60244603024588694],
                'val_acc': [0.17142857183580812, 0.19751552835754727, 0.24472049730164663, 0.29565217420921563,
                            0.37391304407060516, 0.3913043485294958, 0.43229813649787668, 0.4211180122742742,
                            0.42484472160753994, 0.41987577687879529],
                'val_loss': [3.7763777463332469, 3.5307922268506164, 3.2851792984127259, 2.9763647654041741, 2.737886569514778,
                             2.6325608985024211, 2.5756296847918021, 2.7493783006016512, 2.8917108950407608,3.2256962965734255]}

hist_BaseCNN_df = pd.DataFrame(hist_BaseCNN)
hist_BaseCNN_df.columns = ['Train_acc', 'Train_loss', 'Val_acc','Val_loss']
hist_BaseCNN_df

ax1 = hist_BaseCNN_df.plot(marker='.')
ax1.set_xlabel("Epoch")
ax1.set_ylabel("Value")
plt.savefig('base.png')

hist_Aug1 = {'acc': [0.25546875000000002, 0.29408060445893619, 0.30462846340100169, 0.33674433294411571, 0.34146725470833572,
                     0.35941435768261965, 0.35925692687707222, 0.38365868995111596, 0.38727959705239878, 0.40192065483676997,
                     0.4208123424191319, 0.42191435753248202, 0.43938916906601838, 0.45560453385490013, 0.46221662491034499,
                     0.46300377878794441, 0.49071158705190088, 0.48598866498740556, 0.50519521410579349, 0.51243702770780852,
                     0.51338161254109305, 0.53494962246652211, 0.5469143573823444, 0.54738665017433075, 0.54707178841309823,
                     0.55919395450981202, 0.57761335027608218, 0.58705919470534818, 0.58658690161308658, 0.59382871551537697,
                     0.60862720418036431, 0.61319269506396812, 0.60799748125844999, 0.62043450881612094, 0.61791561727860111,
                     0.62641687627403198, 0.63082493747812074, 0.6460957172835804, 0.650818640098764, 0.64798488710028701,
                     0.6527078087143694, 0.66593198977429557, 0.67726700341971757, 0.67742443324937029, 0.67333123395665162,
                     0.67553526448362722, 0.68246221707509802, 0.69285264483627207, 0.7029282120373147, 0.69899244302466179,
                     0.71630982307703128, 0.6985201511335013, 0.71048488634959872, 0.71656249999999999, 0.71505037813402839,
                     0.71977329974811088, 0.7282745596443676, 0.73646095747911655, 0.73803526478390247, 0.75409319944285624],
             'loss': [3.2232321786880491, 2.9990468968071924, 2.9238310268603884, 2.7992355565280098, 2.737023192028555,
                      2.6451771565588658, 2.6298042989197548, 2.5292290740409484, 2.4872682490937357, 2.4218320276034571,
                      2.3226811627596993, 2.299093459655416, 2.2177092599628554, 2.2043386424518654, 2.1157339285843317,
                      2.0904880164552395, 2.0064047355795989, 1.9939596881193837, 1.9514757896250381, 1.9008020567954036,
                      1.876178127392113, 1.782965435489299, 1.7345330483967472, 1.7294392582751641, 1.7163397094764998,
                      1.6662033177743329, 1.6024818057077057, 1.5661355632378413, 1.5691469054978802, 1.5227450225455335,
                      1.469195683597017, 1.4539444128271914, 1.4576934302784033, 1.4022760595422548, 1.3867993583006581,
                      1.3635792876370909, 1.3296321273150311, 1.2845476106071954, 1.265174487676068, 1.2719144436814622,
                      1.2758843298222615, 1.2146366297147737, 1.1755962930338208, 1.163139341460067, 1.1503687775705562,
                      1.1531679134825314, 1.1188850982363339, 1.0898135984574517, 1.0535212247738008, 1.0678208411790862,
                      1.0192861403866438, 1.0809404141356422, 1.0331504585160416, 0.98859515905380246, 1.00419298527523,
                      0.99700506358062591, 0.96955797684282741, 0.93192633513539502, 0.91039594775183075, 0.87640107939165246],
             'val_acc': [0.3828125, 0.39438700367816265, 0.39881831830150094, 0.41802068092094036, 0.44313146339033344,
                         0.46233382715432297, 0.4357459379175741, 0.45963541666666669, 0.49778434414102901, 0.46971935113036301,
                         0.48596750562969304, 0.50516986899749217, 0.50516986987791523, 0.56129985396231652,0.54036458333333337,
                         0.52437223298158742, 0.52732644299460651, 0.55096012248246318, 0.5509601204574901, 0.57607090182635423,
                         0.56129985721988196, 0.5703125, 0.58345642646271156, 0.60265879071093376, 0.58345642646271156,
                         0.59084195171536513, 0.60856720959242194, 0.59379616120013035, 0.62239583333333337,0.64106351806282824,
                         0.61595273519724481, 0.64254062117642807, 0.61742983654999839, 0.66469719640613478,
                         0.62629246579667486, 0.62630208333333337, 0.64844904129050862, 0.63810930505637053,
                         0.62924667906725951, 0.673559824420219, 0.6528803561779738, 0.64401772605087415, 0.65625,
                         0.64254062267314738, 0.63515509856504382, 0.64844904155463556, 0.66322008880237704, 0.6661743015447078,
                         0.68537666227123761, 0.65625, 0.66322008941867328, 0.68094534703160314, 0.67355982265937275,
                         0.70162481439342528, 0.68833087492552603, 0.68389955678049541, 0.68489583333333337, 0.692762186643468,
                         0.68537666517663387, 0.67651403478540728],
             'val_loss': [2.6452309290568032, 2.5847700216217264, 2.4060148689208036, 2.3356332831756053, 2.3420486395609079,
                          2.3017310786282472, 2.3716619233084923, 2.2140320539474487, 2.0899026453759153, 2.1580345694036218,
                          2.0487872564634158, 2.0332463872309448, 2.0096049868725956, 1.9020438509466377, 1.9020523428916931,
                          1.8518806903717966, 1.7829044162786869, 1.8370949434917117, 1.845528794180167, 1.7594302035152825,
                          1.8055269017353368, 1.6822096308072407, 1.7357862992335986, 1.6300792472225172, 1.7285163599772151,
                          1.6977536676553362, 1.6085897534425362, 1.6361149172663161, 1.5901709794998169, 1.484190075929267,
                          1.5790710727432453, 1.5120298226791788, 1.4797959715964346, 1.4832501860453775, 1.5785681849216253,
                          1.554775059223175, 1.4138278459340465, 1.3956891520160692, 1.5429726955281402, 1.3938687219225321,
                          1.4762555027994131, 1.4691717006607281, 1.4483438928922017, 1.4830871012221412, 1.4592810141987427,
                          1.4282475282029528, 1.425352577796891, 1.337258996780373, 1.3461823303202936, 1.4805522759755452,
                          1.3543041685659389, 1.2878402416075703, 1.391042958510327, 1.3276069699573376, 1.279264172035623,
                          1.3356382948961356, 1.367376983165741, 1.3885350897357946, 1.4288017251466896, 1.3429765403710934]}

hist_Aug1_df = pd.DataFrame(hist_Aug1)
hist_Aug1_df.columns = ['Test_acc', 'Test_loss', 'Val_acc','Val_loss']
hist_Aug1_df.head()

ax2 = hist_Aug1_df.plot(marker='.')
ax2.set_xlabel("Epoch")
ax2.set_ylabel("Value")
plt.savefig('aug.png')

